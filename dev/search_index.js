var documenterSearchIndex = {"docs":
[{"location":"api_reference/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api_reference/#RunwayLib.CAMCONF4COMP","page":"API Reference","title":"RunwayLib.CAMCONF4COMP","text":"Camera configuration type for precompilation\n\n\n\n\n\n","category":"constant"},{"location":"api_reference/#RunwayLib.BehindCameraException","page":"API Reference","title":"RunwayLib.BehindCameraException","text":"BehindCameraException\n\nException thrown when the projection point is behind the camera\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RunwayLib.CameraConfig","page":"API Reference","title":"RunwayLib.CameraConfig","text":"struct CameraConfig{S} <: RunwayLib.AbstractCameraConfig{S}\n\nCamera configuration with reference frame S being either :offset or :centered. Check Camera Model for further explanation.\n\nFields\n\nfocal_length_px::Unitful.Quantity{Float64, NoDims, Unitful.FreeUnits{(pixel,), NoDims, nothing}}\nimage_width::Unitful.Quantity{Float64, NoDims, Unitful.FreeUnits{(pixel,), NoDims, nothing}}\nimage_height::Unitful.Quantity{Float64, NoDims, Unitful.FreeUnits{(pixel,), NoDims, nothing}}\n\nExamples\n\nusing RunwayLib, Unitful.DefaultSymbols, Rotations\ncam_pos = WorldPoint(-10m, 0m, 0m)\ncam_rot = RotZYX(zeros(3)...)\nworld_pt = WorldPoint(0m, 0m, 0m)\n\nfocal_length = 25mm\npixel_size = 5Î¼m/px\ncamconf_centered = CameraConfig{:centered}(focal_length, pixel_size, 4096.0px, 2048.0px)\nproject(cam_pos, cam_rot, world_pt, camconf_centered); nothing\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RunwayLib.CameraConfig-Union{Tuple{S}, Tuple{Unitful.Quantity{T, ð‹, U} where {T<:Real, U<:Unitful.Unitlike}, Unitful.Quantity{T, ð‹, U} where {T<:Real, U<:Unitful.Unitlike}, Unitful.Quantity{T, NoDims, U} where {T<:Real, U<:Unitful.Unitlike}, Unitful.Quantity{T, NoDims, U} where {T<:Real, U<:Unitful.Unitlike}}} where S","page":"API Reference","title":"RunwayLib.CameraConfig","text":"CameraConfig{S}(\n    focal_length::WithDims(mm), pixel_size::WithDims(mm / px),\n    image_width::WithDims(px), image_height::WithDims(px)\n)\n\nConvenience constructor for CameraConfig taking focal length and pixel size separately.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RunwayLib.CameraMatrix","page":"API Reference","title":"RunwayLib.CameraMatrix","text":"struct CameraMatrix{S,T<:WithDims(px)} <: AbstractCameraConfig{S}\n\nCamera model using 3x3 projection matrix with uniform pixel units. The reference frame S can either be :offset or :centered. See Camera Model for more explanation.\n\nnote: Note\nNotably it is the users responsibility to construct the matrix such that the axes are aligned correctly, i.e., for S=:offset the first two offdiagonal elements must be negative.\n\nwarning: Warning\nAt this time, only S = :offset is implemented.\n\nExamples\n\nusing StaticArrays, RunwayLib\nf_px = 5e6px  # focal length in pixels\ncx, cy = 2048px, 1024px\nmatrix = SA[\n    -f_px   0px  cx\n    0px   -f_px  cy\n    0px   0px   1px\n]\nCameraMatrix{:offset}(matrix, 2cx, 2cy); nothing\n\nRelated Functions\n\nSee also project.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RunwayLib.CameraPoint","page":"API Reference","title":"RunwayLib.CameraPoint","text":"CameraPoint{T} <: FieldVector{3, T}\n\nPoint in camera coordinate system.\n\nFields\n\nx::T: Camera forward direction (positive towards scene)\ny::T: Camera right direction (positive to the right)\nz::T: Camera down direction (positive downward)\n\nUnits\n\nTypically uses meters (u\"m\") for all coordinates.\n\nCoordinate System Convention\n\nX-axis: Forward (into the scene)\nY-axis: Right (to the right of the camera)\nZ-axis: Down (downward from camera)\n\nThis follows the standard computer vision convention.\n\nExamples\n\n# Point 10m in front of camera, 2m to the right, 1m below\ncp = CameraPoint(10.0u\"m\", 2.0u\"m\", 1.0u\"m\")\n\n# Access coordinates\nprintln(\"Forward: \", cp.x)\nprintln(\"Right: \", cp.y)\nprintln(\"Down: \", cp.z)\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RunwayLib.LineFeatures","page":"API Reference","title":"RunwayLib.LineFeatures","text":"LineFeatures{T, Tâ€²â€², S, WL, OL, CC, M, Mâ€²}\n\nLine feature observations and noise model for pose estimation.\n\nFields\n\nworld_line_endpoints: Vector of pairs of WorldPoints defining lines in world space\nobserved_lines: Vector of Line objects (r, theta) from observations\ncamconfig: Camera configuration\ncov: Covariance matrix for observation errors\nLinv: Inverted lower triangular part of covariance\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RunwayLib.OptimizationConfig","page":"API Reference","title":"RunwayLib.OptimizationConfig","text":"OptimizationConfig\n\nConfiguration parameters for pose estimation optimization.\n\nFields\n\nmax_iterations::Int: Maximum number of optimization iterations\nconvergence_tolerance: Convergence tolerance for residual norm\nstep_tolerance: Minimum step size tolerance\ngradient_tolerance: Gradient norm tolerance for convergence\n\nExamples\n\nconfig = OptimizationConfig(\n    max_iterations = 100,\n    convergence_tolerance = 1e-6*1pixel,\n    step_tolerance = 1e-8,\n    gradient_tolerance = 1e-6\n)\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RunwayLib.PointFeatures","page":"API Reference","title":"RunwayLib.PointFeatures","text":"PointFeatures{T, Tâ€², Tâ€²â€², S, RC, OC, CC, M, Mâ€²}\n\nPoint feature observations and noise model for pose estimation.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RunwayLib.PoseEstimate","page":"API Reference","title":"RunwayLib.PoseEstimate","text":"PoseEstimate\n\nComplete pose estimate with position, attitude, uncertainty, and convergence information.\n\nFields\n\nposition::WorldPoint: Estimated aircraft position in world coordinates\nattitude::RotZYX: Estimated aircraft attitude (yaw, pitch, roll)\nuncertainty::MvNormal: Joint position-attitude uncertainty distribution\nresidual_norm: Final residual norm from optimization (with units)\nconverged::Bool: Whether optimization converged successfully\n\nExamples\n\n# Create pose estimate\nposition = WorldPoint(500.0u\"m\", 10.0u\"m\", 100.0u\"m\")\nattitude = RotZYX(0.1, 0.05, 0.02)  # Small attitude angles\nuncertainty = MvNormal(zeros(6), I(6))  # 6-DOF uncertainty\nresidual_norm = 0.5*1pixel\nconverged = true\n\npose_est = PoseEstimate(position, attitude, uncertainty, residual_norm, converged)\n\n# Access components\nprintln(\"Position: \", pose_est.position)\nprintln(\"Attitude: \", pose_est.attitude)\nprintln(\"Converged: \", pose_est.converged)\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RunwayLib.PoseOptimizationParams3DOF","page":"API Reference","title":"RunwayLib.PoseOptimizationParams3DOF","text":"PoseOptimizationParams3DOF{A, PF, LF}\n\nParameters for 3-DOF pose optimization (position only with known attitude).\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RunwayLib.PoseOptimizationParams6DOF","page":"API Reference","title":"RunwayLib.PoseOptimizationParams6DOF","text":"PoseOptimizationParams6DOF{PF, LF}\n\nParameters for 6-DOF pose optimization (position + attitude).\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RunwayLib.ProjectionPoint","page":"API Reference","title":"RunwayLib.ProjectionPoint","text":"ProjectionPoint{T, S} <: FieldVector{2, T}\n\nPoint in image projection coordinate system.\n\nType Parameters\n\nT: Numeric type for coordinates\nS: Coordinate system type (only :offset supported)\n\nFields\n\nx::T: Image x-coordinate (horizontal pixel position)\ny::T: Image y-coordinate (vertical pixel position)\n\nUnits\n\nTypically uses pixels (1pixel) for coordinates.\n\nCoordinate System Convention\n\nFor :offset coordinates:\n\nOrigin at top-left corner of image\nX-axis: Horizontal (positive to the right)\nY-axis: Vertical (positive downward)\n\nExamples\n\n# Offset coordinates (origin at top-left)\npp_offset = ProjectionPoint{Float64, :offset}(1024.0*1pixel, 768.0*1pixel)\n\n# Access coordinates\nprintln(\"X: \", pp_offset.x)\nprintln(\"Y: \", pp_offset.y)\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RunwayLib.WorldPoint","page":"API Reference","title":"RunwayLib.WorldPoint","text":"WorldPoint{T} <: FieldVector{3, T}\n\nPoint in world coordinate system (runway-relative).\n\nFields\n\nx::T: Along-track distance (positive towards far end of runway)\ny::T: Cross-track distance (positive towards right side of runway)\nz::T: Height above runway surface (positive upward)\n\nUnits\n\nTypically uses meters (u\"m\") for all coordinates.\n\nExamples\n\n# Create a point 500m before runway threshold, 10m right of centerline, 100m high\nwp = WorldPoint(-500.0u\"m\", 10.0u\"m\", 100.0u\"m\")\n\n# Access coordinates\nprintln(\"Along-track: \", wp.x)\nprintln(\"Cross-track: \", wp.y) \nprintln(\"Height: \", wp.z)\n\n# Arithmetic operations\nwp2 = WorldPoint(100.0u\"m\", 0.0u\"m\", 50.0u\"m\")\nwp_sum = wp + wp2  # Element-wise addition\nwp_scaled = 2.0 * wp  # Scalar multiplication\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#Base.inv-Union{Tuple{LinearAlgebra.LowerTriangular{T, <:StaticArraysCore.SMatrix{N, N}}}, Tuple{N}, Tuple{T}} where {T, N}","page":"API Reference","title":"Base.inv","text":"inv(L::LowerTriangular{T, <:SMatrix}) where T\n\nCustom inverse for lower triangular static matrices using forward-substitution. Preserves SMatrix type instead of converting to Matrix.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#Base.inv-Union{Tuple{LinearAlgebra.UpperTriangular{T, <:StaticArraysCore.SMatrix{N, N}}}, Tuple{N}, Tuple{T}} where {T, N}","page":"API Reference","title":"Base.inv","text":"inv(U::UpperTriangular{T, <:SMatrix}) where T\n\nCustom inverse for upper triangular static matrices using back-substitution. Preserves SMatrix type instead of converting to Matrix.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RunwayLib.WithDims-Tuple{Unitful.Quantity}","page":"API Reference","title":"RunwayLib.WithDims","text":"WithDims(q::Quantity)\nWithDims(u::Units)\n\nReturns a subtype of Unitful.Quantity with the dimensions constrained to the dimension of q or u. Useful to build unitful interfaces that don't constrain the numeric type or the unit, just the dimension of a quantity. Examples:\n\njulia> using Unitful, Unitful.DefaultSymbols; import Unitful.hr\n\njulia> using RunwayLib: WithDims\n\njulia> circumference_of_square(side::WithDims(m)) = 4*side;\n\njulia> circumference_of_square((1//2)m)  # works\n2//1 m\n\njulia> circumference_of_square((1//2)km)  # also works\n2//1 km\n\njulia> # You can also constrain the return type. The numeric type is usually inferred automatically.\n\njulia> kinetic_energy(mass::WithDims(kg), velocity::WithDims(m/s))::WithDims(J) = mass*velocity^2;\n\njulia> kinetic_energy(1000kg, 100km/hr)\n10000000 kg km^2 hr^-2\n\nSee also WithUnits.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RunwayLib.WithUnits-Tuple{Unitful.Quantity}","page":"API Reference","title":"RunwayLib.WithUnits","text":"WithUnits(q::Quantity)\nWithUnits(u::Units)\n\nReturns a subtype of Unitful.Quantity with the dimensions and units constrained to the dimension and units of q or u. Useful to build unitful interfaces that don't constrain the unit, but not the numeric type of a quantity. Examples:\n\njulia> using Unitful, Unitful.DefaultSymbols; import Unitful.hr\n\njulia> using RunwayLib: WithUnits\n\njulia> circumference_of_square(side::WithUnits(m)) = 4*side;\n\njulia> circumference_of_square((1//2)m)  # works\n2//1 m\n\njulia> # circumference_of_square((1//2)km)  # doesn't work, constrained to exactly meters\n\njulia> # You can also constrain the return type. The numeric type is usually inferred automatically.\n\njulia> kinetic_energy(mass::WithUnits(kg), velocity::WithUnits(m/s))::WithUnits(J) = mass*velocity^2 |> x->uconvert(J, x);\n\njulia> kinetic_energy(1000kg, uconvert(m/s, 100km/hr))\n62500000//81 J\n\nSee also WithDims.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RunwayLib.cam_pt_to_world_pt-Tuple{WorldPoint, Rotations.RotZYX, CameraPoint}","page":"API Reference","title":"RunwayLib.cam_pt_to_world_pt","text":"cam_pt_to_world_pt(cam_pos::WorldPoint, R::RotZYX, cam_pt::CameraPoint) -> WorldPoint\n\nTransform a point from camera coordinates to world coordinates.\n\nArguments\n\ncam_pos::WorldPoint: Camera position in world coordinates\ncam_rot::RotZYX: Camera orientation (ZYX Euler angles: yaw, pitch, roll)\ncam_pt::CameraPoint: Point to transform in camera coordinates\n\nReturns\n\nWorldPoint: Point in world coordinate system\n\nAlgorithm\n\nRotate point by camera rotation to get world-relative coordinates\nTranslate by camera position to get absolute world coordinates\n\nExamples\n\nusing RunwayLib, Unitful.DefaultSymbols, Rotations\n# Transform camera point back to world coordinates\ncam_pos = WorldPoint(10.0m, 20m, 30m)\ncam_rot = RotZYX(roll=0.0rad, pitch=0rad, yaw=0rad)  # No rotation\ncam_pt = CameraPoint(1.0m, 2m, 3m)\n\nworld_pt = cam_pt_to_world_pt(cam_pos, cam_rot, cam_pt)\n\n# output\n\n3-element WorldPoint{Float64{m}} with indices SOneTo(3):\n 11.0 m\n 22.0 m\n 33.0 m\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RunwayLib.getline-Union{Tuple{Tâ€²}, Tuple{T}, Tuple{ProjectionPoint{T, :offset}, ProjectionPoint{Tâ€², :offset}}} where {T, Tâ€²}","page":"API Reference","title":"RunwayLib.getline","text":"getline(p1::ProjectionPoint, p2::ProjectionPoint) -> Line\n\nConvert two projection points to Hough transform parameters (r, theta). Line represented as: r = xcos(theta) + ysin(theta)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RunwayLib.makecache-Tuple{Any, RunwayLib.AbstractPoseOptimizationParams}","page":"API Reference","title":"RunwayLib.makecache","text":"makecache(uâ‚€, ps::AbstractPoseOptimizationParams)\n\nCreate optimization cache.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RunwayLib.nominal2optvar-Union{Tuple{AT}, Tuple{AT, PoseOptimizationParams3DOF}} where AT","page":"API Reference","title":"RunwayLib.nominal2optvar","text":"From regular space into optimization space.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RunwayLib.optvar2nominal-Union{Tuple{AT}, Tuple{AT, PoseOptimizationParams3DOF}} where AT","page":"API Reference","title":"RunwayLib.optvar2nominal","text":"From optimization space into regular space.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RunwayLib.pose_optimization_objective-Union{Tuple{T}, Tuple{AbstractVector{T}, RunwayLib.AbstractPoseOptimizationParams}} where T<:Real","page":"API Reference","title":"RunwayLib.pose_optimization_objective","text":"pose_optimization_objective(pose_params, ps)\n\nUnified optimization function for pose estimation.\n\nArguments\n\npose_params: Vector of pose parameters\n[x, y, z, roll, pitch, yaw] for 6-DOF\n[x, y, z] for 3-DOF\nps: PoseOptimizationParams6DOF or PoseOptimizationParams3DOF\n\nReturns\n\nWeighted reprojection error vector combining point and line features\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RunwayLib.pose_optimization_objective_lines-Tuple{WorldPoint, Rotations.Rotation, LineFeatures}","page":"API Reference","title":"RunwayLib.pose_optimization_objective_lines","text":"pose_optimization_objective_lines(cam_pos, cam_rot, line_features)\n\nCompute weighted line feature residuals.\n\nArguments\n\ncam_pos: Camera position (WorldPoint)\ncam_rot: Camera rotation (Rotation)\nline_features: LineFeatures struct\n\nReturns\n\nWeighted line error vector (empty if no lines)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RunwayLib.pose_optimization_objective_points-Tuple{WorldPoint, Rotations.Rotation, PointFeatures}","page":"API Reference","title":"RunwayLib.pose_optimization_objective_points","text":"pose_optimization_objective_points(cam_pos, cam_rot, point_features)\n\nCompute weighted point feature residuals.\n\nArguments\n\ncam_pos: Camera position (WorldPoint)\ncam_rot: Camera rotation (Rotation)\npoint_features: PointFeatures struct\n\nReturns\n\nWeighted reprojection error vector\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RunwayLib.project-Union{Tuple{S}, Tuple{Tâ€²}, Tuple{T}, Tuple{WorldPoint{T}, Rotations.RotZYX, WorldPoint{Tâ€²}}, Tuple{WorldPoint{T}, Rotations.RotZYX, WorldPoint{Tâ€²}, CameraConfig{S}}} where {T, Tâ€², S}","page":"API Reference","title":"RunwayLib.project","text":"function project(\n    cam_pos::WorldPoint{T}, cam_rot::RotZYX, world_pt::WorldPoint{Tâ€²},\n    camconfig::CameraConfig{S}=CAMERA_CONFIG_OFFSET\n) where {T,Tâ€²,S}\n\nProject 3D world point to 2D image coordinates using pinhole camera model. See Camera Model for more information.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RunwayLib.project-Union{Tuple{U}, Tuple{S}, Tuple{Tâ€²}, Tuple{T}, Tuple{WorldPoint{T}, Rotations.RotZYX, WorldPoint{Tâ€²}, CameraMatrix{S, U}}} where {T, Tâ€², S, U}","page":"API Reference","title":"RunwayLib.project","text":"function project(\n    cam_pos::WorldPoint{T}, cam_rot::RotZYX, world_pt::WorldPoint{Tâ€²},\n    camconfig::CameraMatrix{S,U}\n) where {T,Tâ€²,S,U}\n\nVersion dispatching on CameraMatrix.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RunwayLib.validate_camera_matrix-Tuple{StaticArraysCore.SMatrix{3, 3}, Any}","page":"API Reference","title":"RunwayLib.validate_camera_matrix","text":"Validate 3x3 matrix for camera projection.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RunwayLib.world_pt_to_cam_pt-Union{Tuple{Tâ€²}, Tuple{T}, Tuple{WorldPoint{T}, Rotations.RotZYX, WorldPoint{Tâ€²}}} where {T<:(Union{Unitful.Quantity{T, ð‹, U}, Unitful.Level{L, S, Unitful.Quantity{T, ð‹, U}} where {L, S}} where {T, U}), Tâ€²<:(Union{Unitful.Quantity{T, ð‹, U}, Unitful.Level{L, S, Unitful.Quantity{T, ð‹, U}} where {L, S}} where {T, U})}","page":"API Reference","title":"RunwayLib.world_pt_to_cam_pt","text":"world_pt_to_cam_pt(cam_pos::WorldPoint, R::RotZYX, world_pt::WorldPoint) -> CameraPoint\n\nTransform a point from world coordinates to camera coordinates.\n\nArguments\n\ncam_pos::WorldPoint: Camera position in world coordinates\ncam_rot::RotZYX: Camera orientation (ZYX Euler angles: yaw, pitch, roll)\nworld_pt::WorldPoint: Point to transform in world coordinates\n\nReturns\n\nCameraPoint: Point in camera coordinate system\n\nAlgorithm\n\nTranslate point relative to camera position\nRotate by inverse of camera rotation to get camera-relative coordinates\n\nExamples\n\nusing RunwayLib, Unitful.DefaultSymbols, Rotations\n# Camera at origin with no rotation\ncam_pos = WorldPoint(0.0m, 0m, 0m)\ncam_rot = RotZYX(roll=0.0rad, pitch=0rad, yaw=0rad)  # No rotation\nworld_pt = WorldPoint(1.0m, 2m, 3m)\n\ncam_pt = world_pt_to_cam_pt(cam_pos, cam_rot, world_pt)\n\n# output\n\n3-element WorldPoint{Float64{m}} with indices SOneTo(3):\n 1.0 m\n 2.0 m\n 3.0 m\n\nWith some rotation:\n\n# Camera with 90-degree yaw rotation\ncam_rot = RotZYX(yaw=Ï€/2rad, roll=0.0rad, pitch=0.0rad)  # 90-degree yaw\nworld_pt = WorldPoint(1.0m, 0.0m, 0.0m)\n\ncam_pt = world_pt_to_cam_pt(cam_pos, cam_rot, world_pt)\n# After rotation, x becomes -y in camera frame\ncam_pt â‰ˆ WorldPoint(0.0m, -1.0m, 0.0m)\n\n# output\n\ntrue\n\n\n\n\n\n","category":"method"},{"location":"C_interface/#C-Interface","page":"C Interface","title":"C Interface","text":"","category":"section"},{"location":"C_interface/","page":"C Interface","title":"C Interface","text":"Beyond the Julia and Python interfaces, we also expose core parts of our library as a ahead-of-time compiled C library using JuliaC.jl. This is currently in a proof-of-concept state since not all public functions are exported, but it will not be hard to expand this once the need is there.","category":"page"},{"location":"C_interface/#Usage-example","page":"C Interface","title":"Usage example","text":"","category":"section"},{"location":"C_interface/","page":"C Interface","title":"C Interface","text":"A usage example can be found at  main.c which we reprint here:","category":"page"},{"location":"C_interface/","page":"C Interface","title":"C Interface","text":"import Markdown\nMarkdown.parse(\"\"\"\n```C\n$(readchomp(joinpath(\"..\", \"..\", \"juliac\", \"main.c\")))\n```\n\"\"\")","category":"page"},{"location":"C_interface/","page":"C Interface","title":"C Interface","text":"Next to the main.c file one can find the Makefile which outlines how to compile using the generated C library.","category":"page"},{"location":"C_interface/","page":"C Interface","title":"C Interface","text":"warning: Warning\nAt this time, only estimate_pose_6dof is properly supported, although there's nothing stopping us from supporting the rest.","category":"page"},{"location":"python_interface/#Python-Interface","page":"Python Interface","title":"Python Interface","text":"","category":"section"},{"location":"python_interface/","page":"Python Interface","title":"Python Interface","text":"Several attempts have been made to make this module easily callable from python. At this time, we recommend using the python package JuliaCall. Simply install juliacall alongside numpy using your favorite method, for instance","category":"page"},{"location":"python_interface/","page":"Python Interface","title":"Python Interface","text":"uv add juliacall\nuv add numpy","category":"page"},{"location":"python_interface/","page":"Python Interface","title":"Python Interface","text":"and use juliacall to install RunwayLib and the PythonCall extension which enables the python API.","category":"page"},{"location":"python_interface/","page":"Python Interface","title":"Python Interface","text":"from juliacall import Main as jl\njl.Pkg.add(url=\"http://github.com/RomeoV/RunwayLib.jl\", rev=\"docs\")  # should land on master asap","category":"page"},{"location":"python_interface/","page":"Python Interface","title":"Python Interface","text":"You only need to do this once. Now you should be able to use RunwayLib from python like so:","category":"page"},{"location":"python_interface/","page":"Python Interface","title":"Python Interface","text":"import numpy as np\nfrom juliacall import Main as jl\njl.seval(\"using RunwayLib, PythonCall\")\njl.seval(\"import RunwayLib: px, m\")\n\npoints2d = [\n    jl.ProjectionPoint(2284.8, 619.32)*jl.px,\n    jl.ProjectionPoint(2355.2, 620.90)*jl.px,\n    jl.ProjectionPoint(2399.5, 903.30)*jl.px,\n    jl.ProjectionPoint(2252.4, 904.09)*jl.px,\n]\npoints3d = [\n    jl.WorldPoint(1600, 15, -8)*jl.m,\n    jl.WorldPoint(1600, -15, -8)*jl.m,\n    jl.WorldPoint(0, -15, 0)*jl.m,\n    jl.WorldPoint(0, 15, 0)*jl.m,\n]\nintrinsic_matrix = np.array(\n    [\n        [-7311.8, 0.0, 2032.3],\n        [0.0, -7311.8, 1707.4],\n        [0.0, 0.0, 1.0],\n    ]\n)\n\ncamconf = jl.CameraMatrix[jl.Symbol(\"offset\")](\n    intrinsic_matrix, jl.px(2048.0), jl.px(1024.0),\n)\n\njl.seval(\"using RunwayLib.Unitful: ustrip\")\nres_jl = jl.estimatepose6dof(points3d, points2d, camconf)\npos = np.asarray(jl.broadcast(jl.ustrip, res_jl.pos))  # or `np.array(..., copy=None)`\nrot = np.asarray(res_jl.rot)\n\nfor i in range(1_000):\n    jl.estimatepose6dof(points3d, points2d, camconf)\n\n# Smoke test assertions\nassert pos.shape == (3,), f\"Expected position shape (3,), got {pos.shape}\"\nassert rot.shape == (3, 3), f\"Expected rotation shape (3, 3), got {rot.shape}\"\nprint(f\"âœ“ Smoke test passed! Position: {pos}, Rotation shape: {rot.shape}\")\n","category":"page"},{"location":"python_interface/","page":"Python Interface","title":"Python Interface","text":"Notice that we can also directly wrap np.array for WorldPoint and the other, e.g.:","category":"page"},{"location":"python_interface/","page":"Python Interface","title":"Python Interface","text":"points2d_np = [\n    np.array([2284.8, 619.32]),\n    np.array([2355.2, 620.90]),\n    np.array([2399.5, 903.30]),\n    np.array([2252.4, 904.09]),\n]\npoint2d = [jl.ProjectionPoint(p) for p in points2d_np]","category":"page"},{"location":"noise_models/#Noise-Models","page":"Noise Models","title":"Noise Models","text":"","category":"section"},{"location":"noise_models/","page":"Noise Models","title":"Noise Models","text":"TODO: Write this section.","category":"page"},{"location":"camera_model/#Camera-Model","page":"Camera Model","title":"Camera Model","text":"","category":"section"},{"location":"camera_model/","page":"Camera Model","title":"Camera Model","text":"We use the pinhole camera model without any distortion. We implement two projection plane reference frames: :centered and :offset, which are defined as illustrated here:","category":"page"},{"location":"camera_model/","page":"Camera Model","title":"Camera Model","text":"using Typstry\nrender(typst\"\"\"\n       #include \"./figs/camera_models.typ\"\n       \"\"\"; output=\"camera_models.svg\", open=false)","category":"page"},{"location":"camera_model/","page":"Camera Model","title":"Camera Model","text":"(Image: For offset, u point right and v points down. and the origin is in the top left. For centered, u points left and v points up, and the origin is at the image center.)","category":"page"},{"location":"camera_model/","page":"Camera Model","title":"Camera Model","text":"We also support defining the camera model either through CameraConfig or through CameraMatrix.","category":"page"},{"location":"camera_model/#:offset-vs-:centered","page":"Camera Model","title":":offset vs :centered","text":"","category":"section"},{"location":"camera_model/","page":"Camera Model","title":"Camera Model","text":"using RunwayLib, Unitful.DefaultSymbols, Rotations\ncam_pos = WorldPoint(-10m, 0m, 0m)\ncam_rot = RotZYX(zeros(3)...)\nworld_pt = WorldPoint(0m, 0m, 0m)\n\nfocal_length = 25mm\npixel_size = 5Î¼m/px\ncamconf_centered = CameraConfig{:centered}(focal_length, pixel_size, 4096.0px, 2048.0px)\nproject(cam_pos, cam_rot, world_pt, camconf_centered)","category":"page"},{"location":"camera_model/","page":"Camera Model","title":"Camera Model","text":"With an offset camera model:","category":"page"},{"location":"camera_model/","page":"Camera Model","title":"Camera Model","text":"camconf_offset = CameraConfig{:offset}(focal_length, pixel_size, 4096.0px, 2048.0px)\nproject(cam_pos, cam_rot, world_pt, camconf_offset)","category":"page"},{"location":"camera_model/","page":"Camera Model","title":"Camera Model","text":"And for a non-centered point:","category":"page"},{"location":"camera_model/","page":"Camera Model","title":"Camera Model","text":"world_pt2 = WorldPoint(0m, 1m, 1m)\nproject(cam_pos, cam_rot, world_pt2, camconf_centered)","category":"page"},{"location":"camera_model/","page":"Camera Model","title":"Camera Model","text":"project(cam_pos, cam_rot, world_pt2, camconf_offset)","category":"page"},{"location":"camera_model/#Line-Projections","page":"Camera Model","title":"Line Projections","text":"","category":"section"},{"location":"camera_model/","page":"Camera Model","title":"Camera Model","text":"For :offset camera models, we also currently support line features. Lines are specified with respect to a reference point chosen to be the \"offset origin\" and parameterized by their Hough transform, i.e., the angle and radius.","category":"page"},{"location":"camera_model/","page":"Camera Model","title":"Camera Model","text":"using Typstry\nrender(typst\"\"\"\n  #include \"./figs/line_parameterization.typ\"\n  \"\"\"; output=\"line_parameterization.svg\", open=false)","category":"page"},{"location":"camera_model/","page":"Camera Model","title":"Camera Model","text":"(Image: )","category":"page"},{"location":"camera_model/#Reference","page":"Camera Model","title":"Reference","text":"","category":"section"},{"location":"camera_model/#RunwayLib.project-camera_model","page":"Camera Model","title":"RunwayLib.project","text":"function project(\n    cam_pos::WorldPoint{T}, cam_rot::RotZYX, world_pt::WorldPoint{Tâ€²},\n    camconfig::CameraConfig{S}=CAMERA_CONFIG_OFFSET\n) where {T,Tâ€²,S}\n\nProject 3D world point to 2D image coordinates using pinhole camera model. See Camera Model for more information.\n\n\n\n\n\nfunction project(\n    cam_pos::WorldPoint{T}, cam_rot::RotZYX, world_pt::WorldPoint{Tâ€²},\n    camconfig::CameraMatrix{S,U}\n) where {T,Tâ€²,S,U}\n\nVersion dispatching on CameraMatrix.\n\n\n\n\n\n","category":"function"},{"location":"camera_model/#RunwayLib.CameraConfig-camera_model","page":"Camera Model","title":"RunwayLib.CameraConfig","text":"struct CameraConfig{S} <: RunwayLib.AbstractCameraConfig{S}\n\nCamera configuration with reference frame S being either :offset or :centered. Check Camera Model for further explanation.\n\nFields\n\nfocal_length_px::Unitful.Quantity{Float64, NoDims, Unitful.FreeUnits{(pixel,), NoDims, nothing}}\nimage_width::Unitful.Quantity{Float64, NoDims, Unitful.FreeUnits{(pixel,), NoDims, nothing}}\nimage_height::Unitful.Quantity{Float64, NoDims, Unitful.FreeUnits{(pixel,), NoDims, nothing}}\n\nExamples\n\nusing RunwayLib, Unitful.DefaultSymbols, Rotations\ncam_pos = WorldPoint(-10m, 0m, 0m)\ncam_rot = RotZYX(zeros(3)...)\nworld_pt = WorldPoint(0m, 0m, 0m)\n\nfocal_length = 25mm\npixel_size = 5Î¼m/px\ncamconf_centered = CameraConfig{:centered}(focal_length, pixel_size, 4096.0px, 2048.0px)\nproject(cam_pos, cam_rot, world_pt, camconf_centered); nothing\n\n\n\n\n\n","category":"type"},{"location":"camera_model/#RunwayLib.CameraMatrix-camera_model","page":"Camera Model","title":"RunwayLib.CameraMatrix","text":"struct CameraMatrix{S,T<:WithDims(px)} <: AbstractCameraConfig{S}\n\nCamera model using 3x3 projection matrix with uniform pixel units. The reference frame S can either be :offset or :centered. See Camera Model for more explanation.\n\nnote: Note\nNotably it is the users responsibility to construct the matrix such that the axes are aligned correctly, i.e., for S=:offset the first two offdiagonal elements must be negative.\n\nwarning: Warning\nAt this time, only S = :offset is implemented.\n\nExamples\n\nusing StaticArrays, RunwayLib\nf_px = 5e6px  # focal length in pixels\ncx, cy = 2048px, 1024px\nmatrix = SA[\n    -f_px   0px  cx\n    0px   -f_px  cy\n    0px   0px   1px\n]\nCameraMatrix{:offset}(matrix, 2cx, 2cy); nothing\n\nRelated Functions\n\nSee also project.\n\n\n\n\n\n","category":"type"},{"location":"python_interface_template/#Python-Interface","page":"Python Interface","title":"Python Interface","text":"","category":"section"},{"location":"python_interface_template/","page":"Python Interface","title":"Python Interface","text":"Several attempts have been made to make this module easily callable from python. At this time, we recommend using the python package JuliaCall. Simply install juliacall alongside numpy using your favorite method, for instance","category":"page"},{"location":"python_interface_template/","page":"Python Interface","title":"Python Interface","text":"uv add juliacall\nuv add numpy","category":"page"},{"location":"python_interface_template/","page":"Python Interface","title":"Python Interface","text":"and use juliacall to install RunwayLib and the PythonCall extension which enables the python API.","category":"page"},{"location":"python_interface_template/","page":"Python Interface","title":"Python Interface","text":"from juliacall import Main as jl\njl.Pkg.add(url=\"http://github.com/RomeoV/RunwayLib.jl\", rev=\"docs\")  # should land on master asap","category":"page"},{"location":"python_interface_template/","page":"Python Interface","title":"Python Interface","text":"You only need to do this once. Now you should be able to use RunwayLib from python like so:","category":"page"},{"location":"python_interface_template/","page":"Python Interface","title":"Python Interface","text":"{{PYTHON_EXAMPLE}}","category":"page"},{"location":"python_interface_template/","page":"Python Interface","title":"Python Interface","text":"Notice that we can also directly wrap np.array for WorldPoint and the other, e.g.:","category":"page"},{"location":"python_interface_template/","page":"Python Interface","title":"Python Interface","text":"points2d_np = [\n    np.array([2284.8, 619.32]),\n    np.array([2355.2, 620.90]),\n    np.array([2399.5, 903.30]),\n    np.array([2252.4, 904.09]),\n]\npoint2d = [jl.ProjectionPoint(p) for p in points2d_np]","category":"page"},{"location":"#RunwayLib.jl","page":"RunwayLib.jl: Fast Pose Estimation and Runtime Assurance for Runway Landings.","title":"RunwayLib.jl","text":"","category":"section"},{"location":"#Getting-Started","page":"RunwayLib.jl: Fast Pose Estimation and Runtime Assurance for Runway Landings.","title":"Getting Started","text":"","category":"section"},{"location":"","page":"RunwayLib.jl: Fast Pose Estimation and Runtime Assurance for Runway Landings.","title":"RunwayLib.jl: Fast Pose Estimation and Runtime Assurance for Runway Landings.","text":"using RunwayLib, Unitful.DefaultSymbols, Rotations\n\nrunway_corners = [\n    WorldPoint(0.0m, 50m, 0m),     # near left\n    WorldPoint(3000.0m, 50m, 0m),  # far left\n    WorldPoint(3000.0m, -50m, 0m),  # far right\n    WorldPoint(0.0m, -50m, 0m),    # near right\n]\n\ncam_pos = WorldPoint(-2000.0m, 12m, 150m)\ncam_rot = RotZYX(roll=1.5Â°, pitch=5Â°, yaw=0Â°)\n\ntrue_observations = [project(cam_pos, cam_rot, p) for p in runway_corners]\nnoisy_observations = [p + ProjectionPoint(2.0*randn(2)px) for p in true_observations]\n\n(cam_pos_est, cam_rot_est) = estimatepose6dof(\n    PointFeatures(runway_corners, noisy_observations)\n)[(:pos, :rot)]\n\ncam_pos_est","category":"page"},{"location":"","page":"RunwayLib.jl: Fast Pose Estimation and Runtime Assurance for Runway Landings.","title":"RunwayLib.jl: Fast Pose Estimation and Runtime Assurance for Runway Landings.","text":"We can extract roll-pitch-yaw as","category":"page"},{"location":"","page":"RunwayLib.jl: Fast Pose Estimation and Runtime Assurance for Runway Landings.","title":"RunwayLib.jl: Fast Pose Estimation and Runtime Assurance for Runway Landings.","text":"import Rotations: params\n(yaw, pitch, roll) = params(cam_rot_est)\n@show rad2deg(roll*rad)\n@show rad2deg(pitch*rad)\n@show rad2deg(yaw*rad)\n;","category":"page"},{"location":"#Using-Line-Features","page":"RunwayLib.jl: Fast Pose Estimation and Runtime Assurance for Runway Landings.","title":"Using Line Features","text":"","category":"section"},{"location":"","page":"RunwayLib.jl: Fast Pose Estimation and Runtime Assurance for Runway Landings.","title":"RunwayLib.jl: Fast Pose Estimation and Runtime Assurance for Runway Landings.","text":"Besides point features we can additionally include line features which can typically improve our altitude and crosstrack estimations, but usually can't improve our alongtrack estimation much because the line projections are constant along the glidepath. See Line Projections for more information on the line parameterization.","category":"page"},{"location":"","page":"RunwayLib.jl: Fast Pose Estimation and Runtime Assurance for Runway Landings.","title":"RunwayLib.jl: Fast Pose Estimation and Runtime Assurance for Runway Landings.","text":"line_pts = [\n    (runway_corners[1], runway_corners[2]),\n    (runway_corners[3], runway_corners[4]),\n]\ntrue_lines = map(line_pts) do (p1, p2)\n    proj1 = project(cam_pos, cam_rot, p1)\n    proj2 = project(cam_pos, cam_rot, p2)\n    getline(proj1, proj2)\nend\nobserved_lines = [\n  Line(\n    r + 1px*randn(),\n    theta + deg2rad(1Â°)*randn()\n  )\n  for (; r, theta) in true_lines\n]\n\n# now with additional line features\n(cam_pos_est, cam_rot_est) = estimatepose6dof(\n    PointFeatures(runway_corners, noisy_observations),\n    LineFeatures(line_pts, observed_lines)\n)[(:pos, :rot)]\n\ncam_pos_est","category":"page"},{"location":"integrity_check/#Integrity-Check","page":"Integrity Check","title":"Integrity Check","text":"","category":"section"},{"location":"integrity_check/","page":"Integrity Check","title":"Integrity Check","text":"TODO: Write this section.","category":"page"}]
}
